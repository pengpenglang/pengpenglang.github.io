---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

ğŸ‘‹ Hello, here is pengpenglang, a junior computer vision alchemist!

ğŸ» Feel free to reach out if you share similar interests â€” let's learn and grow together!

ğŸ™‚ My research focuses on **Gait Recognition** and **Human Pose Estimation**. I'm also interested in **Multimodal LLM** and **3D Vision**. 

# ğŸ“– Educations
- **M.Eng. in Computer Science and Technology, Beijing Normal University, [BNU-IVC](https://github.com/BNU-IVC)**

  *2023.09 - Present*, GPA: 3.60/4.0, Supervisor: [Prof. Yongzhen Huang](https://ai.bnu.edu.cn/xygk/szdw/zgj/bfed57e2f8fc4de2a6b370063517f801.htm) (Co-Supervisor: [Prof. Saihui Hou](https://ai.bnu.edu.cn/xygk/szdw/fgj/170e0faaf01d4a0e8c50a6c889c786c3.htm))

- **B.Eng. in Computer Science and Technology, China University of Geosciences (Beijing)**

  *2019.09 - 2023.06*, GPA: 4.69/5.0, Supervisor: [Prof. Yuqing Zhang](https://www.cupk.edu.cn/gxy/c/2024-09-24/524112.shtml)


# ğŸ”¥ News
- *2025.11*: ğŸ¥³ One paper has been accepted by AAAI 2026 (CCF-A, Student-first-author).
- *2025.07*: ğŸ¥³ One paper has been accepted by ACM MM 2025 (CCF-A, Oral, First-author). 

# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2026</div><img src='images/GaT.png' alt="sym" width="100%"></div></div>

<div class='paper-box-text' markdown="1">

**Gait Transformer: End-to-End Transformer Backbone for Gait Recognition**

Saihui Hou, ***Wenpeng Lang***, Jilong Wang, Yan Huang, Liang Wang, Yongzhen Huang<sup>â€ </sup>

[**[ğŸ“œPaper]**]() [**[ğŸ–¼ï¸Poster]**]() [**[ğŸ§©Code]**]()<br/>
We propose GaT, an end-to-end Transformer for gait recognition. It addresses spatial-temporal dynamics, fine-grained motion, and data scarcity via three modules: hybrid patch embedding with group-batch bormalization, decomposed token mixer for context dependencies, and hybrid positional encoding strategy. Without any pretraining, GaT achieves SOTA performance on popular datasets.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACM MM 2025 Oral</div><img src='images/DPGait.png' alt="sym" width="100%"></div></div>

<div class='paper-box-text' markdown="1">

**Beyond Sparse Keypoints: Dense Pose Modeling for Robust Gait Recognition**

***Wenpeng Lang***, Saihui Hou, Yongzhen Huang<sup>â€ </sup>

[**[ğŸ“œPaper]**](https://dl.acm.org/doi/pdf/10.1145/3746027.3755685) [**[ğŸŒWebsite]**](https://dpgait.github.io/) [**[ğŸ¬Video]**](https://dpgait.github.io/static/videos/DPGait.mp4) [**[ğŸ§©Code]**](https://github.com/DPGait/DPGait)<br/>
We propose DPGait, a dense pose-based method to solve the limitations of sparse keypoints. On the upstream, we extend estimation model to output human dense points. On the downstream, we design a divide-and-conquer modeling architecture. Our method achieves SOTA performance across three datasets, demonstrating the effectiveness of method in complex scenarios.
</div>
</div>

# ğŸ… Awards
- [ACM ICPC Asia Regional Contest](https://icpc.global), ğŸ¥‰Bronze Medal, 2022 & 2023.
- [China Group Programming Ladder Tournament](https://gplt.patest.cn), ğŸ†Champion, 2022.
- [American COMAP MCM/ICM Contest](https://www.comap.com/contests/mcm-icm), ğŸ…Finalist, 2022.
- [China Collegiate Mathematical Modeling Contest](https://en.mcm.edu.cn), ğŸ¥ˆSecond Prize, 2021.
- [CCPC Regional Contest](https://ccpc.io/), ğŸ¥‰Bronze Medal, 2021.

# ğŸ¤  Experience
- *2020.09 - 2022.09*, Captain of the [CUGB-ACM](https://sai.cugb.edu.cn/c/2018-11-01/656924.shtml).

# ğŸŒ± Miscellaneous
- My creed is *â€œOn the ship of life, be a happy pirateâ€*.
- Love to learn any interesting thing: ğŸŠï¸, ğŸ¸, ğŸ¸, ğŸ¨, ğŸ® and so on.
